{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "from vpt.features.features import *\n",
    "import vpt.utils.image_processing as ip\n",
    "import vpt.settings as s\n",
    "\n",
    "from keras import models\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [\"p1\", \"p3\", \"p4\", \"p5\", \"p6\"]\n",
    "base_folder = \"data/posture\"\n",
    "hand_folder = \"hand_data_M3_rad.3\"\n",
    "\n",
    "size = (120, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data\n",
    "\n",
    "X_lh = np.array([])\n",
    "y_lh = np.array([])\n",
    "X_rh = np.array([])\n",
    "y_rh = np.array([])\n",
    "filenames = np.array([])\n",
    "\n",
    "for p in participants:\n",
    "      \n",
    "    folder = os.path.join(base_folder, p, hand_folder)\n",
    "    X_lh = np.concatenate( (X_lh, np.load(os.path.join(folder, \"X_lh.npy\"))))\n",
    "    y_lh = np.concatenate( (y_lh, np.load(os.path.join(folder, \"y_lh.npy\"))))\n",
    "    X_rh = np.concatenate( (X_rh, np.load(os.path.join(folder, \"X_rh.npy\"))))\n",
    "    y_rh = np.concatenate( (y_rh, np.load(os.path.join(folder, \"y_rh.npy\"))))\n",
    "    filenames = np.concatenate( (filenames, np.load(os.path.join(folder, \"filenames.npy\"))))\n",
    "    \n",
    "print(\"LH:\", X_lh.shape, y_lh.shape)\n",
    "print(\"RH:\", X_rh.shape, y_rh.shape)\n",
    "print(\"Filenames:\", filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lh_ds = np.zeros((len(X_lh), size[0], size[1]))\n",
    "X_rh_ds = np.zeros((len(X_rh), size[0], size[1]))\n",
    "\n",
    "for i, (lh, rh) in enumerate(zip(X_lh, X_rh)):\n",
    "    X_lh_ds[i] = resize(ip.normalize(lh), size, preserve_range=True)\n",
    "    X_rh_ds[i] = resize(ip.normalize(rh), size, preserve_range=True)\n",
    "    \n",
    "X_lh_ds = X_lh_ds[:,:,:, np.newaxis]\n",
    "X_rh_ds = X_rh_ds[:,:,:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cae_lh = models.load_model(\"data/cae/hands/lh_20171207_encoder_model.h5\")\n",
    "cae_rh = models.load_model(\"data/cae/hands/rh_20171207_encoder_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_lh = cae_lh.predict(X_lh_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_rh = cae_lh.predict(X_rh_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_lh.shape\n",
    "encoded_imgs_rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_lh = np.reshape(encoded_imgs_lh, (17622, 15*12*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_rh = np.reshape(encoded_imgs_rh, (17622, 15*12*50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_lh.shape\n",
    "encoded_imgs_rh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/posture/all/encoded/encoded_imgs_lh.npy\", encoded_imgs_lh)\n",
    "np.save(\"data/posture/all/encoded/encoded_imgs_rh.npy\", encoded_imgs_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_lh = np.load(\"data/posture/all/encoded/encoded_imgs_lh.npy\")\n",
    "encoded_imgs_rh = np.load(\"data/posture/all/encoded/encoded_imgs_rh.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lh_pca = PCA(n_components=\"mle\", svd_solver=\"full\").fit_transform(encoded_imgs_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lh_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/posture/all/encoded/encoded_pca_lh.npy\", X_lh_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "soundfile ='duetta1.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(url=soundfile, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all \"static\" data so we can ignore for now\n",
    "r = re.compile('p[\\d]s')\n",
    "# r2 = re.compile('p[\\d]d')\n",
    "\n",
    "# remove p#s data\n",
    "vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "rem_static = vmatch(filenames)\n",
    "\n",
    "X_lh2, y_lh2, filenames2 = X_lh_pca[~rem_static], y_lh[~rem_static], filenames[~rem_static]\n",
    "\n",
    "# seperate p3 from data\n",
    "r_p3 = re.compile('/p3/')\n",
    "vmatch = np.vectorize(lambda x:bool(r_p3.search(x)))\n",
    "sel = vmatch(filenames2)\n",
    "\n",
    "#augment data with SMOTE (but first split it so we have some good testing data)\n",
    "# X_train_lh, X_test_lh, y_train_lh, y_test_lh = train_test_split(X_lh2, y_lh2, test_size=.20)\n",
    "X_train_lh, X_test_lh, y_train_lh, y_test_lh = X_lh2[~sel], X_lh2[sel], y_lh2[~sel], y_lh2[sel]\n",
    "X_smote_lh, y_smote_lh = SMOTE(kind='svm').fit_sample(X_train_lh, y_train_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Data sets\n",
    "print(\"SMOTE:\", X_smote_lh.shape, y_smote_lh.shape)\n",
    "print(\"TEST:\", X_test_lh.shape, y_test_lh.shape)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.hist(y_smote_lh, bins=3, rwidth=.5)\n",
    "plt.title(\"SMOTE Training Labels\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(y_test_lh, bins=3, rwidth=.5)\n",
    "plt.title(\"Test data Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Models selected in previous notebook (see model selection)\n",
    "C = 100\n",
    "gamma = .1\n",
    "kernel = 'rbf'\n",
    "clf_svm = SVC(C=C, gamma=gamma, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf_svm, X_smote_lh, y_smote_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scores:\", scores)\n",
    "print(\"Avg Score:\", np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm.fit(X_smote_lh, y_smote_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test_lh, clf_svm.predict(X_test_lh)\n",
    "print(\"Test Set Accuracy Score:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confustion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Piano Tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Project Description\n",
    "\n",
    "This is a notebook for tracking my progress on VPT...\n",
    "\n",
    "- Best Classifier as of 11/30\n",
    "    - SVM {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODAY\n",
    "    - Generate data from already extracted hands...\n",
    "    - Rewrite RDF for GridSearchCV\n",
    "        - Extend RDF\n",
    "    - Organize RDF data\n",
    "    - Add results to file\n",
    "    \n",
    "- DONE\n",
    "    - ~~Get notebook running on Compute Canada~~\n",
    "    - ~~Get data on Compute Canada~~\n",
    "    - ~~Setup CAE to deal with hand images~~\n",
    "    - ~~setup data for training autoencoder on LH and RH~~\n",
    "    - ~~Train Autoencoder for LH and Rh~~\n",
    "    \n",
    "\n",
    "- Bad Segmentation\n",
    "    - p3c - left hand (not terrible)\n",
    "    - p1s - right hand (shouldn't use)\n",
    "    - p5a - Both could use some work but still caputures most of the left hand (RH not so good...)\n",
    "    - p5c - not good (left hand passable...)\n",
    "    \n",
    "- Add noise to CAE\n",
    "    - http://scikit-image.org/docs/dev/api/skimage.util.html#random-noise\n",
    "    \n",
    "- ~~Multiple Participants~~\n",
    "    - ~~have one holdout set participant~~\n",
    "        - ~~Test with p1&2 training p3 testing, then p1&3...~~\n",
    "    - ~~have one holdout set exercise~~\n",
    "\n",
    "- Test with RH too\n",
    "\n",
    "- Windowing data\n",
    "    - Summarize data for classification\n",
    "    - Majority Voting (or with probabilities)\n",
    "\n",
    "- Look for other features\n",
    "    - Autoencoder features\n",
    "    - ~~HONV~~\n",
    "    \n",
    "- Work on hand segmentation\n",
    "   - See p1e for bad examples\n",
    "   - How to validate segmentation?\n",
    "       - Statistical analysis on length and width ratios\n",
    "       \n",
    "- Visualize !!!\n",
    "    - Input \n",
    "    - Results !!!\n",
    "        - F Scores\n",
    "        - Accuracy\n",
    "        - Try weighted instead of macro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Finish Project Description\n",
    "\n",
    "- ~~Turn into functions~~\n",
    "    \n",
    "- ~~Verify Segmentation~~\n",
    "    - have only done basic verification\n",
    "    \n",
    "- ~~FIRST THING: Test by ignoring training data (p1s) and then using train_test_split on recordings~~\n",
    "    - ~~Data should be ready for spliting~~\n",
    "    \n",
    "- ~~Remove data from testing to find culprit~~\n",
    "    \n",
    "- ~~Track my progress better !!! (duh through notebooks!)~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from vpt.features.features import *\n",
    "import vpt.utils.image_processing as ip\n",
    "import vpt.settings as s\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hand(hand):\n",
    "    dmap = hand.get_original()\n",
    "    mask = hand.get_mask()\n",
    "        \n",
    "    img = (ip.normalize(dmap)*255).astype('uint8')\n",
    "    img_hand = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"OG\", img)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Hand Only\", img_hand)\n",
    "    \n",
    "    return cv2.waitKey(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_hand_detector(M, radius, n_samples, folder, ftype, annotation_file):\n",
    "    annotations = load_annotations(annotation_file)\n",
    "\n",
    "    # generate or load model\n",
    "    segmentation_model_path = \"data/rdf/trainedmodels/p4_M%i_rad%0.1f\" % (M, radius)\n",
    "    rdf_hs = load_hs_model('p4', M, radius, n_samples, refreshHD, segmentation_model_path, masks=\"seq_masks\")\n",
    "\n",
    "    fs = FileStream(folder, ftype, annotations=annotations, ignore=True)\n",
    "    hd = HandDetector(rdf_hs)\n",
    "    \n",
    "    return hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(fs, hd, annotations):\n",
    "\n",
    "    X_lh = []\n",
    "    y_lh = []\n",
    "    training_idxs_lh = []\n",
    "\n",
    "    X_rh = []\n",
    "    y_rh = []\n",
    "    training_idxs_rh = []\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    hg = HandGenerator(fs, hd, annotations)\n",
    "\n",
    "    hgen = hg.hand_generator(debug=True)\n",
    "    for lh, rh in hgen:\n",
    "        if lh.label() != None and rh.label() != None:\n",
    "\n",
    "            if (s.participant != \"p0\" and s.participant != \"p9\") and \"{}s\".format(s.participant) in lh.get_fpath():\n",
    "                training_idxs_lh.append(i)\n",
    "            elif (s.participant == \"p0\" and \"p0a\" in lh.get_fpath() or \"p0b\" in lh.get_fpath()) or (s.participant == \"p9\" and \"p9a\" in lh.get_fpath() or \"p9b\" in lh.get_fpath()):\n",
    "                training_idxs_lh.append(i)\n",
    "\n",
    "            filenames.append(lh.get_fpath())\n",
    "            y_lh.append(lh.label())\n",
    "            X_lh.append(extract_features(lh.get_hand_img(), feature_type, n_slices=n_slices))\n",
    "            \n",
    "            i+=1\n",
    "            \n",
    "        else:\n",
    "            raise RuntimeWarning(\"Warning: No label found for hands\")\n",
    "\n",
    "    X_lh = np.array(X_lh)\n",
    "    y_lh = np.array(y_lh)\n",
    "    filenames = np.array(filenames)\n",
    "\n",
    "    training_mask_lh = np.zeros((len(y_lh),), dtype=bool)\n",
    "    training_mask_lh[training_idxs_lh] = True\n",
    "    \n",
    "    return X_lh, y_lh, training_mask_lh, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Save Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(X_lh, y_lh, training_mask, filenames, participant, M, radius, feature_type):\n",
    "\n",
    "    data_path = os.path.join(\"data/posture\", participant, \"models/M{}_rad{:0.1f}_{}\".format(M, radius, feature_type))\n",
    "    np.save(data_path + \".full_data_lh.npy\", np.hstack((X_lh, np.expand_dims(y_lh, 1))))\n",
    "    np.save(os.path.join(\"data/posture\", participant, \"models/training_mask_lh.npy\"), training_mask_lh)\n",
    "    np.save(os.path.join(\"data/posture\", participant, \"models/filenames.npy\"), filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(participant, M, radius, feature_type):\n",
    "    data_path = os.path.join(\"data/posture\", participant, \"models/M{}_rad{:0.1f}_{}\".format(M, radius, feature_type))\n",
    "    data_lh = np.load(data_path + \".full_data_lh.npy\")\n",
    "    training_mask_lh = np.load(os.path.join(\"data/posture\", participant, \"models/training_mask_lh.npy\"))\n",
    "    filenames = np.load(os.path.join(\"data/posture\", participant, \"models/filenames.npy\"))\n",
    "\n",
    "    X_lh = data_lh[:, :-1].squeeze()\n",
    "    y_lh = data_lh[:,j -1].squeeze()\n",
    "    \n",
    "    return X_lh, y_lh, training_mask_lh, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Some General Parameters\n",
    "s.participant = \"all\"\n",
    "s.sensor = \"realsense\"\n",
    "s.note = \"all_data_11_30\"\n",
    "\n",
    "ftype = \"bin\"\n",
    "folder = \"data/posture/all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Parameters\n",
    "\n",
    "refreshHD = False\n",
    "refreshCLF = True\n",
    "\n",
    "## RDF Parameters\n",
    "M = 3\n",
    "radius = .3\n",
    "n_samples = 500\n",
    "\n",
    "## Posture Detection Parameters\n",
    "feature_type = \"hog\"\n",
    "n_slices = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Existing Data\n",
    "X_lh, y_lh, training_mask_lh, filenames = load_data(s.participant, M, radius, feature_type)\n",
    "print(\"X LH:\", X_lh.shape)\n",
    "print(\"y LH:\", y_lh.shape)\n",
    "print(\"Training LH:\", training_mask_lh.shape)\n",
    "print(\"File names:\", filenames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17622, 9000) (17622,)\n",
      "(17622, 9000) (17622,)\n",
      "(17622,)\n"
     ]
    }
   ],
   "source": [
    "X_lh_og = np.load(\"data/posture/all/encoded/encoded_imgs_lh.npy\")\n",
    "y_lh = np.load(\"data/posture/all/encoded/y_lh.npy\")\n",
    "X_rh_og = np.load(\"data/posture/all/encoded/encoded_imgs_lh.npy\")\n",
    "y_rh = np.load(\"data/posture/all/encoded/y_rh.npy\")\n",
    "filenames = np.load(\"data/posture/all/encoded/filenames.npy\")\n",
    "\n",
    "print(X_lh_og.shape, y_lh.shape)\n",
    "print(X_rh_og.shape, y_rh.shape)\n",
    "print(filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "pca_lh = PCA(n_components=750, svd_solver='auto')\n",
    "X_lh = pca_lh.fit_transform(X_lh_og)\n",
    "print(pca_lh.n_components_)\n",
    "\n",
    "pca_rh = PCA(n_components=750, svd_solver='auto')\n",
    "X_rh = pca_rh.fit_transform(X_rh_og)\n",
    "print(pca_rh.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all \"static\" data so we can ignore for now\n",
    "r = re.compile('p[\\d]s')\n",
    "\n",
    "# remove p#s data\n",
    "vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "rem_static = vmatch(filenames)\n",
    "\n",
    "X_lh, y_lh, filenames = X_lh[~rem_static], y_lh[~rem_static], filenames[~rem_static]\n",
    "\n",
    "# seperate p3 from data\n",
    "r_p3 = re.compile('/p3/')\n",
    "vmatch = np.vectorize(lambda x:bool(r_p3.search(x)))\n",
    "sel = vmatch(filenames)\n",
    "\n",
    "X_lh2, y_lh2 = X_lh[~sel], y_lh[~sel]\n",
    "\n",
    "#augment data with SMOTE (but first split it so we have some good testing data)\n",
    "# X_train_lh, X_test_lh, y_train_lh, y_test_lh = train_test_split(X_lh2, y_lh2, test_size=.20)\n",
    "X_train_lh, X_test_lh, y_train_lh, y_test_lh = X_lh2, X_lh[sel], y_lh2, y_lh[sel]\n",
    "X_smote_lh, y_smote_lh = SMOTE(kind='svm').fit_sample(X_train_lh, y_train_lh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: (24227, 750) (24227,)\n",
      "TEST: (2650, 750) (2650,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x2abf3d63ec50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs8AAAEICAYAAACgdxkmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X+8ZVV93//Xmx+VaAQkjoFhBoeOQRQHrQ5JY2hJiMYg\nKXSgSEyTiiEZbSBJ4WuNJdY2JqmaMg22gVhMYDRUsBh+6iRaQisYRb5jmomDBgUZmDv4YxQEFAWB\nT//Y68qZO3fm7nu5P86Z+3o+Hucx+6y99t6ffWbfdT93nb32SlUhSZIkaWp7LXQAkiRJ0qgweZYk\nSZJ6MnmWJEmSejJ5liRJknoyeZYkSZJ6MnmWJEmSejJ51qKUZCzJS2a77nxIcnaSK2a47a8kuWa2\nY5KkvpJ8K8mKhY5jV5L88ySfmOG2P5tk42zHpOFi8rzIJPnHSW5K8lCS+5P8dZLj2rrVSSrJjRO2\neV4r/9sJ5a9N8rdJvpvkq0kuTnJQW/fOts1krztanW9Nsu6PJon5it3s64YZfhRvBcbmoG5vSX4+\nyd/P9n4laaIk++2mHa0kvzjD/X49yYtmO9627597KolokmOTfGs2Y5LA5HlRSbIf8GFgA3AosBL4\nfeCxgWoPA89Lsnyg7F8BX5iwrzcAFwHvBH4Y+ElgOXBDkqfRJZw/0F7nAJ8ceP/CgV399ED5DwD/\nZpLQf2lg/QXA5QPvT5jkPPfZ3ecAUFXrq+rrU9Wbbl1JGkZV9V12bGu/Abx64P0HFi46abSYPC8u\nK4AfAi6oqger6r6q2lBVfz1Qp+iS018ESBLgXwJ/Nl6hJeHvAP6/qrqiqh6oqs8DpwKHAK+rqseq\n6rutwX4MqPH3VfXowPEeHSj/blUNJvJdQFXfG9jX48ATA/W/l+RFSb6S5N8n+SxwcZKlSf5Xkm+0\nnpEPJDlw4By+fytGkvOTXJrkuiSbk2xM8oIZ1j26lT3Q6lyS5Pem+x+V5NeTfLF9Q/D5JGsmVHla\nksvacf4uycsHtt0/yZ8k+XKSbUl+L8nekxxjn/Ztwfb2LcTfTfijSdIeZLCtbUWDbStJ3pLkztZm\nXp7kWa38gCRXt/b0viSfTrJvkj8FngV8NMmWJKdPdtwk5ya5t73OmrDutUlua23dnUl+tZU/C/hT\nYFXb95Ykeyf56SR/k+TBJFuTvG0mn8Wujrtjlby7tY1fSPLPBlY8rf0uuKf97rmw/V6c7Dj/qdX5\nZpK/zxDdAqiZM3leXLYA24D1SV413jBO4s/oensB/gnwFeCOgfWr6RrMKwc3qqqHgeuAV85izH39\nMPBYVa0CzqS7tt9N18N+BPBsYHeN7EnAb1bVi+j+eFg33bqtx/saus/voHb8187wfLbR9cofALwZ\neH+SgwfW/zPgI+045wPXJfnBtu4S4Gl05/2Stp9fmeQYpwJHAYe3/bwWeGiG8Uoabb8BnAYcT9du\nPgD817bubOC7dJ0jS1rdJ6rqTOB+4FVVtaKqPjhxp0leCfwW8ArgHwI/StfTPe6bwBpgf7rfO/8l\nyYuq6n66tvyzbd8rqupx4NFWfiDwKuANSV49g/Od9LgD638MuJvud8evA1ckWdbWvQt4EfBS4Efo\nvnX97UnO/SeAfwG8sKoOBE4EvjqDWDVkTJ4Xkda78BN0X9f9EfC1JBsm9jZW1Wbgu0leRnfLxvsn\n7OrZwLerarJE68ttfV8fbr0c46/XTWPbQY/RktjqjFXVh1uvyn3AH9D9IbArV1XVXW15A12jON26\nPwrsB/zXqnq8qv4K+KuZnExVXVVV91TVE1V1PbAJeNlAlb+tqsvbcd4P3Au8MskPAafQJfcPVdV2\nunM/bZLDfI/uj6CjgFTVbVX1zZnEK2nkvQH4j1V1d1U9Qnfr3ant28fvAQcDR7Q259Mtke3jtcAl\nVfW59jvorQzkHlX1F1X1hdZuf5KuU+AndrWzqrq5qv5vaxs/R9dZsbu2fVf7meq4XwP+sJ3vR4GP\nA2va5/GrwL+tqq+334O/y67b2B8EXpxk36q6s6q+PN1YNXymvDdUe5aquhs4CyDJUuBS4E/o/oIf\n9GfAWroezn87Yf3XgWckeeYkCfQhbX1frwf+/4H3909j20H3Dd4OkuSZdMn0T9L1cuwNPLKb7b8x\nsPwdugZvunWXAtuqqgbWb50y8kkk+Tng39H1aDwBPIcd/yiZuN+72/Gf2+p/smvjge7nfLL/k2vo\neqcvAX44yeXAm6vqOzOJWdJIey7w7iT/eaDs23TfSv0R3S1/1yfZl+53xu9MaOt2ZSlwy/ibqtqa\n5Pu35yU5Fvgduh7cJ9pxPrurnSU5im6szYvokvD9gQ/1OcEJ+5nquBPb8vE2dgnwdOBDScbX70XX\ncbKDqro1ye/QfTu4Msm1wDmtQ0cjzJ7nRayq7qVrBI+eZPUH6BLbm9rXZ4M+Q/eV1w5/aSd5Ot0t\nDdPpbd3eeonHX9+exraDJjbiv03X6K+uquV093Bnp61m15eBQzOQtdIlv9OSZH+6W2J+q6oOq6oV\nwEZ2jH/ifg+j633eSvdZvKyqjmyv51XVP554nNZz886qOoqu9/zHmfz2Dkl7vq3Arwy0G0dW1ZKq\n+kZVPVxVv1VVhwM/Q9dO/Gzb7okp9nsv3W11AKR7ItM+bTnAVcAfAytaW3c9T7Z1k+37fcCNwI9U\n1XPbttNq23scF3Zuy8fb2K/TdZqcMPA5HVFVh012rKr671X1MrqOioPpbmHRiDN5XkSSHJ7kPyY5\nMt1ji54HvBH49MS6VfVV4Djg3EnWfYcuOV2X5PQ2mORI4M/pvupaP42w/kGLZfy17wxObTIHAF+q\nqgfbvci/Nkv73Z1b6Xq3fyPJXkl+mu5+493JhPPfjyfvB/xcq/CjwMTk9yVJXtOO84t09yje0G7T\nuA64MMlB6axMexzhhAP/eLoBjnsB97XYvzfDc5c02t4DvLP9XiDJkiQnteVXJlnZ6n2drp0Ybyu+\nBjxvN/v9IPBLeXLA9uATlfYGngn8XVU90Y49eP/y1+iS2MFe3QOA26rqsSRL6DGuZJI2dp8pjgvd\nt32/2QYpvpLuW8xrquoJ4L3Af2vf3pJkWZKfmeS4Ryf5sXQDth+g68m3jd0DmDwvLg/SPXHjL+l+\nkG+mG5i2drLKVfWpqpr0toOquohuEMl5dA3c+L6OrydHcvfxV3R/xY+/rtx99d7eBRyb5FN0PQo7\n/YEw26rqe3T3G/8rup7536T7OnF3t4scwY7n/x1gX7rBjZ9K8lHgdXSf76DrgZPpbnN5C7Bm4Baa\n19M9cnBTi+NDdLfTTPTDdL/Yvkk3IPSzdKPbJS0+76ZrDz6S5CHgU8Axbd2P0D2G9EHgb4D3VdX4\nM/Z/D/ij9jSJX5q403a/8MXAJ5L8L7rfQ99u6x4D/jXdgOcbgH8PfHRg888A/wfY1va/N91gxT9M\n8r/peo43THFez2DnNvZlUxwXut8Z/5Duj4U/Bv7lwO/D36JrXz/ZPpOPtc9oov3bud9P17P/CN0Y\nFI249LtlSdJMJNkAXFlVly50LJIk6amz51maRUn+Sfu6M23Q3z+l6+mXJEl7AJ+2Ic2uo+huPdmP\n7mu60300kSRJew57nqVZVFXvqaqDq+rAqlpVVR9Z6Ji0+KSbfXJ7ks2TrDsrSY0PDGtl5yS5K91M\na6cOlK9Ksind7G6XZJKZKiVpsTF5lqQ9z3vZ+ekBpJulcg3wxYGylXTPfj+a7gk7F7THTgJcCJzX\nHuV1IDDp9MuStJgM/W0bz372s2vFihULHYYkTdtnPvOZr1fVkvk+blV9fLBnecD5dI+ZfN9A2UnA\n1e1pLQ8luRU4PskngSN58mkGl9I9+eUDuzu2bbakUdW3zR765HnFihVs3LhxocOQpGlLcvdCxzAu\nySuA71TVp3ec+4FDgbGB91tb2VLg3oFZ1sbLJ9v3WtojLw877DDbbEkjqW+b7W0bkrSHS/IP6J7H\n++8mWz3h/V5TlO+kqi6uqtVVtXrJknnvaJekeWXyLEl7vkOBlcDGJFva8v9JcgRdr/OygbrL6CY8\n2gYsHZiieLxckhY1k2dJ2sNV1V1VtaSqVrTBf3cCP1lVX6CbrXJNkv2TLKebVe7GqroPuB04se3m\nDOCa+Y9ekoaLybMk7WGSXEU3pfvzk4wlOXNXdavqDuAiYDNwE3BuVT3cVp8NvCPJGN20ypfPbeSS\nNPyGfsCgJGl6quqUKdYfOeH9OmDdJPU2AatmNzpJGm32PEuSJEk9mTxLkiRJPZk8S5IkST31Sp6T\nvDHJ59vrmiTPbCOzNyS5K8nNbdrX8frntPI7k5w6UL4qyaYkW5JckmTvuTgpSZIkaS5MOWAwybOA\n3wWOqKr7k7wfOBM4CLitql6d5DeAtwNrk6wEzgKOBg4APpXkL9ro7QuB86rqI200+OlMMdXrTK14\ny0fmYrdDYcs7T5y60ojak//fwP+7UbUn/79JT8We/HMP/uxrcn16ntNe+7We4h8A7gVOBta3OuuB\nNW35JODqqnqoqsaAW4HjkxwEHAlsaPUuBXY7IlySJEkaJlMmz+1B+W8B7qBLmvetqv9JN2PVtlbn\nQWDfJPsNljdbW9lS4N6qqgnlO0myNsnGJBu3b98+oxOTJEmSZtuUyXOSZwC/DLyALtl9NMmv0fVG\n71AVqEnK9xpY3+vYVXVxVa2uqtVLliyZKkRJkiRpXvS5bePlwP1VdU9VPUY3PeuxwBiwDCDJAcCj\nVfXIYHmzjK4nehuwNEkmlEuSJEkjoU/yfA/w0iRLWuL7M8DngeuAM1qdM4Br2/L1wJr2NI7lwDHA\nje32j9uBEwe2uWYWzkGSJEmaF1M+baOqbk+yDrgFeALYBFxAl3hfkWQrXYJ9Wqt/R5KLgM3A48C5\n7UkbAGcDlyV5D3ADcPksn48kSZI0Z6ZMngGq6nzg/ElWnbCL+uuAdZOUbwJWTSdASZIkaVg4w6Ak\nSZLUk8mzJEmS1FOv2zYkSZpLe/JMdc5SJ+1Z7HmWJEmSejJ5liRJknoyeZYkSZJ6MnmWJEmSejJ5\nliRJknoyeZYkSZJ6MnmWJEmSejJ5lqQ9TJLLkmxPsnmg7J1J7m6vP09ywMC6c5LcleTOJKcOlK9K\nsinJliSXJNl7vs9FkoaNybMk7XneC7x6QtmtwAuBFcA3gPMAkqwEzgKOBo4DLkjy9LbNhcB5VbUC\nOBA4fa4Dl6RhZ/IsSXuYqvo4cP+Esquq6ttVVcDNwKFt1UnA1VX1UFWN0SXZxyc5CDgS2NDqXQqc\nMi8nIElDzORZkhaRJAFeB3y4FR0KbBuosrWVLQXubcn2YPlk+1ybZGOSjdu3b5+bwCVpSJg8S9Li\n8nvAV6rqivY+E9bvNUX5Tqrq4qpaXVWrlyxZMkthStJwMnmWpEUiyVnAjwK/PFA8BiwbeL+Mrid6\nG7C09VQPlkvSojZl8pzk+UnGBl7fSfLmJPsn2dBGaN+c5OCBbRy5LUlDJMnP092usaaqHh1YdT2w\nprXpy4FjgBur6j7gduDEVu8M4Jp5DFmShtKUyXNV3V5Vy6pqGbAc+BpwNfAm4LaqOhy4Eng7OHJb\nkhZakqvoBgWOd36cCfwBsBL4+1Z2OUBV3QFcBGwGbgLOraqH267OBt6RZAx4ELh8nk9FkobOPtOs\nfyzwtar6YpKTgV9o5euBO4G1DIzcBh5KMj5y+5PsPHL7dcAHntopSJIGVdVkT8X4093UXwesm6R8\nE7BqFkOTpJE33Xuef4Enk93vj9CuqgeBfZPshyO3JUmStIfqnTwn2YfuGZ+7GqEdoCYpd+S2JEmS\n9gjT6Xl+FbC5qr7c3n9/hHab5vXRqnoER25LkiRpDzWd5Hnwlg2A6+hGX9P+vbYtO3JbkiRJe6Re\nyXN7WsbPAn8+UHw+cFSSrcBrgLeBI7clSZK05+r1tI2W/P7QhLIHgBN2Ud+R25IkSdrjOMOgJEmS\n1JPJsyRJktSTybMkSZLUk8mzJEmS1JPJsyRJktSTybMkSZLUk8mzJEmS1JPJsyRJktSTybMkSZLU\nk8mzJEmS1JPJsyRJktSTybMkSZLUk8mzJEmS1JPJsyRJktSTybMkSZLUk8mzJEmS1JPJsyTtYZJc\nlmR7ks0DZfsn2ZDkriQ3Jzl4YN05rfzOJKcOlK9KsinJliSXJNl7vs9FkoZNr+Q5yZIk1yX5SpIv\nJflHNsSSNLTeC7x6QtmbgNuq6nDgSuDtAElWAmcBRwPHARckeXrb5kLgvKpaARwInD73oUvScOvb\n8/we4BbgEODFwN3YEEvSUKqqjwP3Tyg+GVjfltcDa9ryScDVVfVQVY0BtwLHJzkIOBLY0OpdCpwy\nh2FL0kiYMnluPcrHAn9QnYeq6j5siCVplBwKbAOoqgeBfZPsN1jebG1lS4F7q6omlO8kydokG5Ns\n3L59+1zFL0lDoU/P8/OAe4D3Jflcu93iGdgQS9IoySTva5LyvQbWT1a+k6q6uKpWV9XqJUuWPLUo\nJWnI9Ume9wFeCvwx8CLgceDN2BBL0igZA5YBJDkAeLSqHhksb5bRdYBsA5YmyYRySVrU+iTPY8BX\nquoTVfUEcBXwEmyIJWmUXAec0ZbPAK5ty9cDa9og8OXAMcCN7fa824ETB7a5Zr6ClaRhNWXyXFV3\nANuTHN2KXglsxoZYkoZSkquAm4HnJxlLciZwPnBUkq3Aa4C3wffb+Ivo2vWbgHOr6uG2q7OBdyQZ\nAx4ELp/fM5Gk4bNPz3pvBC5r9zR/Fng93W0YV7SG+B7gNOga4iTjDfHj7NwQX5bkPcAN2BBL0qyr\nql0Nxj5hF/XXAesmKd8ErJrF0CRp5PVKnqvqFrpHz01kQyxJkqRFwxkGJUmSpJ5MniVJkqSeTJ4l\nSZKknkyeJUmSpJ5MniVJkqSeTJ4lSZKknkyeJUmSpJ5MniVJkqSeTJ4lSZKknkyeJUmSpJ5MniVJ\nkqSeTJ4lSZKknkyeJUmSpJ5MniVJkqSeTJ4lSZKknkyeJUmSpJ56Jc9JticZa6/bW9n+STYkuSvJ\nzUkOHqh/Tiu/M8mpA+WrkmxKsiXJJUn2nv1TkiRJkuZG357nx6tqWXs9v5W9Cbitqg4HrgTeDpBk\nJXAWcDRwHHBBkqe3bS4EzquqFcCBwOmzcxqSJEnS3Hsqt22cDKxvy+uBNW35JODqqnqoqsaAW4Hj\nkxwEHAlsaPUuBU55CseXJEmS5lXf5HnvJF9McluSN7SyQ4FtAFX1ILBvkv0Gy5utrWwpcG9V1YRy\nSZIkaSTs07PeMVW1JcnhwEeT3AZkQp0ANUn5XgPrJyvfSZK1wFqAww47rGeIkiRJ0tzq1fNcVVva\nv3cB1wGrgTFgGUCSA4BHq+qRwfJmGV1P9DZgaZJMKJ/seBdX1eqqWr1kyZLpnpMkaRJJ3pjk8+11\nTZJnzmTwtyQtZlMmz0meleQ5bfk5wAnAZ+mS6DNatTOAa9vy9cCa1iAvB44Bbqyq+4DbgRMHtrlm\nVs5CkrRbSZ4F/C7w8qp6AfAgcCYzG/wtSYtWn57nQ4Cbk2wDPg38WVX9FXA+cFSSrcBrgLcBVNUd\nwEXAZuAm4Nyqerjt62zgHUnG6Bruy2fzZCRJu5T22q89JvQHgHuZ5uDv+QxYkobRlPc8V9XngOdP\nUv4AXS/0ZNusA9ZNUr4JWDX9MCVJT0VV3ZfkLcAdwLeAT1XV/0xyEQODv5MMDv4eG9jFLgd5O05F\n0mLiDIOStAgkeQbwy8AL6JLgR5P8GtMf/L0Tx6lIWkxMniVpcXg5cH9V3VNVj9GNOTmW6Q/+lqRF\nzeRZkhaHe4CXJlnSnnr0M8Dnmebg73mNWJKGUN/nPEuSRlhV3Z5kHXAL8ASwCbiArhPlijb4+x7g\ntFb/jnY/9GbgcXYc/C1Ji5bJsyQtElV1Pt2Tkiaa1uBvSVrMvG1DkiRJ6snkWZIkSerJ5FmSJEnq\nyeRZkiRJ6snkWZIkSerJ5FmSJEnqyeRZkiRJ6snkWZIkSerJ5FmSJEnqyeRZkiRJ6snkWZIkSerJ\n5FmSJEnqqXfynGSvJLck+UR7v3+SDUnuSnJzkoMH6p7Tyu9McupA+aokm5JsSXJJkr1n93QkSZKk\nuTOdnuc3AF8aeP8m4LaqOhy4Eng7QJKVwFnA0cBxwAVJnt62uRA4r6pWAAcCpz+l6CVJkqR51Ct5\nTvIcukT3woHik4H1bXk9sKYtnwRcXVUPVdUYcCtwfJKDgCOBDa3epcApTyV4SZIkaT717XleB7wV\neHyg7FBgG0BVPQjsm2S/wfJmaytbCtxbVTWhfCdJ1ibZmGTj9u3b+56LJEmSNKemTJ6T/BTwRFV9\nYuKqSd7XJOV7DazvdeyquriqVlfV6iVLlkwVoiRJkjQv9ulR5+XAK5JsAZ4GPCvJdcAYsAz4ZpID\ngEer6pEk4+XjlgEfo+uNXpokrfd5GTv2UEuSJElDbcqe56r6/ao6tA3yWwNsrKqTgOuAM1q1M4Br\n2/L1wJr2NI7lwDHAjVV1H3A7cOLANtfMzmlIkiRJc69Pz/OunA9ckWQrcA9wGkBV3ZHkImAz3T3S\n51bVw22bs4HLkrwHuAG4/CkcX5IkSZpX00qeq+oW4Ni2/ABwwi7qraMbZDixfBOwavphSpIkSQvP\nGQYlSZKknkyeJWkRSbIkyXVJvpLkS0n+0UxmjJWkxcrkWZIWl/cAtwCHAC8G7mZmM8ZK0qJk8ixJ\ni0TrUT4W+IPqPNSehDStGWPnN2pJGi4mz5K0eDyP7ulI70vyuSSXJHkG058xdgfOCitpMTF5lqTF\nYx/gpcAfAy+ie5zom5n+jLE7cFZYSYuJybMkLR5jwFeq6hNV9QRwFfASnpwxlsEZYwfLG2eGlbTo\nmTxL0iJRVXcA25Mc3YpeSTeh1bRmjJ23gCVpCD2VGQYlSaPnjXQzve4HfBZ4Pd3tGdOdMVaSFiWT\nZ0laRNpMsUdPsmpaM8ZK0mLlbRuSJElSTybPkiRJUk8mz5IkSVJPJs+SJElSTybPkiRJUk8mz5Ik\nSVJPJs+SJElST1Mmz0n2SnJrki1J7k5yfjr7J9mQ5K4kNyc5eGCbc1r5nUlOHShflWRT29clSfae\nqxOTJEmSZtuUyXNVPQGcVFUrgOcDLwdeBbwJuK2qDgeuBN4OkGQlcBbdQ/iPAy5I8vS2uwuB89q+\nDgROn82TkSRJkuZSr9s2quorA/XHtzkZWN+W1wNr2vJJwNVV9VBVjQG3AscnOQg4EtjQ6l0KnPJU\ngpckSZLmU+97npPcBnwD+CzwUeBQYBtAVT0I7Jtkv8HyZmsrWwrcW1U1oXyyY61NsjHJxu3bt0/v\njCRJkqQ50jt5rqqjgEOAlcCPAZlQJUBNUr7XwPpex66qi6tqdVWtXrJkSd8QJUmSpDk1radtVNU3\n6Xqdfw4YA5YBJDkAeLSqHhksb5bR9URvA5YmyYRySZIkaST0edrGc5I8ty0fSHev8+eB64AzWrUz\ngGvb8vXAmvY0juXAMcCNVXUfcDtw4sA218zKWUiSJEnzYJ8edQ4EPpTkh4DHgP8BfADYH7giyVbg\nHuA0gKq6I8lFwGbgceDcqnq47ets4LIk7wFuAC6fzZORJEmS5tKUyXNVfYHusXMTPQCcsItt1gHr\nJinfBKyaZoySJEnSUHCGQUmSJKknk2dJkiSpJ5NnSZIkqSeTZ0mSJKknk2dJkiSpJ5NnSZIkqSeT\nZ0laRJLsleSWJJ9o7/dPsiHJXUluTnLwQN1zWvmdSU5duKglaXiYPEvS4vIG4EsD798E3FZVhwNX\nAm8HSLISOIvuOf/HARckefo8xypJQ8fkWZIWiSTPAU4HLhwoPhlY35bXA2va8knA1VX1UFWNAbcC\nx89PpJI0vEyeJWnxWAe8FXh8oOxQYBtAVT0I7Jtkv8HyZmsr20mStUk2Jtm4ffv2OQlckoaFybMk\nLQJJfgp4oqo+MXHVJO9rkvJd/r6oqouranVVrV6yZMlTD1aShtg+Cx2AJGlevBx4RZItwNOAZyW5\nDhgDlgHfTHIA8GhVPZJkvHzcMuBj8xyzJA0de54laRGoqt+vqkOragXdfc0bq+ok4DrgjFbtDODa\ntnw9sKY9jWM5cAxw47wGLUlDyJ5nSVrczgeuSLIVuAc4DaCq7khyEbCZ7h7pc6vq4YULU5KGg8mz\nJC0yVXULcGxbfgA4YRf11tENMpQkNd62IUmSJPU0ZfKcZHmSG5KMtVmmzm7l056VKsmqJJuSbEly\nSZK95+a0JEmSpNnXt+f57cBy4MeBtyR5ITOblepC4Lw2YOVAuof1S5IkSSNhyuS5qrZW1U3V+Rpw\nO7CUac5KleQg4EhgQ6t3KXDKbJ2IJEmSNNemdc9zkiOAI4BPM/1ZqZYC91ZVTSiXJEmSRkLv5DnJ\ngXS3Z6ytqoeY/qxUvWercqpXSZIkDaNeyXPrUb4WeHdV/UUr/v7sU4OzUg2WN8voeqK3AUuTZEL5\nTpzqVZIkScOoz9M29gY+CPxlVV0ysGpas1JV1X1090ufOLDNNU8xfkmSJGne9Ol5Po5uEOBZ7XF1\nY0nW0M1KdVSbleo1wNugm5UKGJ+V6iZ2nJXqbOAdScaAB4HLZ/VsJEmSpDk05QyDVXUjO9+vPG5a\ns1JV1SZg1XQClCRJkoaFMwxKkiRJPZk8S5IkST2ZPEuSJEk9mTxLkiRJPZk8S5IkST2ZPEuSJEk9\nmTxLkiRJPZk8S5IkST2ZPEuSJEk9mTxLkiRJPZk8S5IkST2ZPEuSJEk9mTxL0iKRZHmSG5KMJbkz\nydmtfP8kG5LcleTmJAcPbHNOK78zyakLF70kDQeTZ0laXN4OLAd+HHhLkhcCbwJuq6rDgStbHZKs\nBM4CjgaOAy5I8vQFiVqShoTJsyQtElW1tapuqs7XgNuBpcDJwPpWbT2wpi2fBFxdVQ9V1RhwK3D8\n/EYtScPF5FmSFqEkRwBHAJ8GDgW2AVTVg8C+SfYbLG+2trKJ+1qbZGOSjdu3b5/z2CVpIZk8S9Ii\nk+RAutsz1lbVQ0AmVgFqkvJJf2dU1cVVtbqqVi9ZsmTW45WkYTJl8pzksiTbk2weKJv24JIkq5Js\nSrIlySUFgS77AAAHz0lEQVRJ9p7905Ek7U7rUb4WeHdV/UUrHgOWtfUHAI9W1SOD5c0yduyJlqRF\np0/P83uBV08om8ngkguB86pqBXAgcPpTjl6S1FvrtPgg8JdVdcnAquuAM9ryGXTJNcD1wJrWYbIc\nOAa4cX6ilaThNGXyXFUfB+6fUDytwSVJDgKOBDa0epcCpzylyCVJ03UcXTt9Vntc3ViSNcD5wFFJ\ntgKvAd4GUFV3ABcBm4GbgHOr6uGFCV2ShsM+M9xuh8ElSQYHl4wN1BsfXLIUuLeqakL5pJKsBdYC\nHHbYYTMMUZI0qKpuZOf7mMedsItt1gHr5iwoSRoxMx0wON3BJb0GnYxz8IkkSZKG0UyT5+kOLtkG\nLE2SCeWSJEnSyJhp8jytwSVVdR/dw/hPHNjmmhkeW5IkSVoQU97znOQqumlcn51kDPgPdINLrmiD\nS+4BToNucEmS8cElj7Pj4JKzgcuSvAe4Abh8tk9GkiRJmktTJs9VtaunYkxrcElVbQJWTSs6SZIk\naYg4w6AkSZLUk8mzJEmS1JPJsyRJktSTybMkSZLUk8mzJEmS1JPJsyRJktSTybMkSZLUk8mzJEmS\n1JPJsyRJktSTybMkSZLUk8mzJEmS1JPJsyRJktSTybMkSZLU0z4LHYAkSZLm14q3fGShQ5gzW955\n4pzu355nSZIkqSeTZ0mSJKknk2dJkiSpp3lPnpP8VJLbk2xJ8vvzfXxJUn+22ZK0o3lNnpME+BPg\nNOB5wCuSvHw+Y5Ak9WObLUk7m++e55cA91XV31XVY8BlwCnzHIMkqR/bbEmaYL4fVXcosG3g/VZg\np16MJGuBte3tt5LcPg+xATwb+Po8HWvG8q6RiHMUYoR5jjPvmtFmfpazZ0YxzvD/DeC5M95yOAx7\nmw0jcN2NSJsNI/BZMhptNvhZzqZpxznXbfZ8J8+Z8H7Snu+quhi4eO7D2VGSjVW1er6PO12jEOco\nxAijEecoxAijEecoxDhkhrrNhtH4Px2FGGE04hyFGGE04hyFGGE445zv2zbGgGUD75exY6+GJGl4\n2GZL0gTznTxvAg5K8uIk+wK/CFwzzzFIkvqxzZakCeY1ea6qJ4BfBT4EfAm4sao+MZ8xTGFBvnac\ngVGIcxRihNGIcxRihNGIcxRiHBoj0GbDaPyfjkKMMBpxjkKMMBpxjkKMMIRxpqoWOgZJkiRpJDjD\noCRJktSTybMkSZLU06JJnqeaYjbJv0lyZ5K7k9yQZHkr/8EkjyUZa68bFjDGs5M8MBDLGwbW/XyL\n/0tJzpqrGHvG+d8HYvxqkm+lM5+f5WVJtifZvIv1+yZ5fzuH/5vkBQPr5uWz7BHjgl+TPeNc8Ouy\nR4wLfk1qekahze4Z5zD8fNhmz1+cC35djkKb3TPOBb8ud6mq9vgX3bNK7wSOpnu29aeBl0+ocyLw\nrLb828AH2/IPAncMSYxnA2+dZNtn0j0+6lBg/7af5QsV54T6ZwL/Yz4/y3as44BjgM27WP/LwJVt\n+STgYwvwWU4V44Jek9OIcxiuy93GOAzXpK9p/X8OfZs9jTgX9OfDNnve4xyG63Lo2+w+cQ7Ddbmr\n12LpeZ5yitmq+khV3d/e3kR38QxVjLvxCuCTVbWtqh6ke5TUyUMS5y8AH5ijWHapqj4O3L+bKicD\n69vy9cBLkjyTefwsp4pxCK7J8Tim+ix3ZWg+ywkW5JrUtIxCmw2j0W7bZs9jnMNwXY5Cmw2j3W4v\nluR5silmd3dBvx748MD7Ze1rjL9JsmYuAqR/jL/evra6evzroGlsOxt6HyvJIcCLgI8NFM/HZ9nH\n98+juj9l7wWWMr+f5XQsxDU5HQt9XfYy5NeknjQKbTaMRrttm71whrndHok2G4bzulwsyXOvKWYB\nkvwqcDiwrhV9BziiqlbS/SBclOTwBYrxSmAFsBK4Fbh0GtvOlukc6+eBq6rqe+39fH2WfezqPObz\ns+xlAa/JvobhuuxrmK9JPWkU2mwYjXbbNnsBDHm7vdDX5HQN3XU5LB/MXOs1xWySk4B/Dfzz8f+k\nqnq8qu5py5uAvwZevBAxVtVXq+o7VfU48N+A1X23nc84B+zwNcs8fpZ9fP88kgQ4hK4nY6imI17g\na7KXIbku+xrma1JPGoU2u1ecQ/DzYZs9z4bgutytIbgmp2v4rsuFvOF6vl50fyR8qX24+9L9pXUs\nsAp4fqvzT4HPA4dM2PYQYP+2vJLuh/WIBYrxCJ6c2OZs4Oa2PH6T/zK6m/y/BBy2UJ9lq/cjwN3j\n8c7nZzlwvOcxMBBhwmd5Jk8OPjkZuGG+P8seMS7oNTmNOBf8upwqxmG5Jn31/r8c+jZ7GnEu6M9H\nnxhbvQX/+ZiinRmKNrtHnAt+XfaIcSja7KniHJbrctK45/NgC/kCfhr4It09PO9sZecDb2nLNwEP\n0P3lNTZwMR3fLqBtwBeAMxYwxj/kyb+0b5xwgf0CsAW4B/iNhfws2/v/ALxrwnbz+VleBXwZ+F77\nvM6c8FnuSzdwZgzYBLxwvj/LHjEu+DXZM84Fvy6ninEYrklf0/4/Hfo2u2ecw/DzYZs9f3Eu+HXZ\nI8YFvyb7xDkM1+WuXk7PLUmSJPW0WO55liRJkp4yk2dJkiSpJ5NnSZIkqSeTZ0mSJKknk2dJkiSp\nJ5NnSZIkqSeTZ0mSJKmn/we7l/Y0/FDGbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2abef19b1048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Data sets\n",
    "print(\"SMOTE:\", X_smote_lh.shape, y_smote_lh.shape)\n",
    "\n",
    "print(\"TEST:\", X_test_lh.shape, y_test_lh.shape)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(y_smote_lh, bins=3, rwidth=.5)\n",
    "plt.title(\"SMOTE Training Labels\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(y_test_lh, bins=3, rwidth=.5)\n",
    "plt.title(\"Test data Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Tuning hyper-parameters for f1\n",
      "\n",
      "Best Parameters set found on data set:\n",
      "\n",
      "{'gamma': 0.1, 'kernel': 'rbf', 'C': 100}\n",
      "\n",
      "Grid scores on data set:\n",
      "\n",
      "0.276 (+/-0.002) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 0.01}\n",
      "0.275 (+/-0.000) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 0.01}\n",
      "0.275 (+/-0.000) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 0.01}\n",
      "0.636 (+/-0.082) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 0.1}\n",
      "0.310 (+/-0.052) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 0.1}\n",
      "0.275 (+/-0.000) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 0.1}\n",
      "0.733 (+/-0.168) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 1}\n",
      "0.630 (+/-0.098) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 1}\n",
      "0.317 (+/-0.053) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 1}\n",
      "0.764 (+/-0.158) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 10}\n",
      "0.725 (+/-0.161) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 10}\n",
      "0.621 (+/-0.101) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 10}\n",
      "0.771 (+/-0.160) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 100}\n",
      "0.751 (+/-0.148) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 100}\n",
      "0.714 (+/-0.152) for {'gamma': 0.001, 'kernel': 'rbf', 'C': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on full SMOTE data set.\n",
      "The scores on computed on the full TEST data set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      0.96      0.74      1267\n",
      "        1.0       0.92      0.41      0.57      1336\n",
      "        2.0       0.33      0.06      0.11        47\n",
      "\n",
      "avg / total       0.75      0.67      0.64      2650\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Parameters for SVMs\n",
    "param_grid = [\n",
    "  {'C': [.01, .1, 1, 10, 100], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "# Hyper Parameter Tuning\n",
    "for score in scores:\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        print(\"## Tuning hyper-parameters for {}\".format(score))\n",
    "        print()\n",
    "\n",
    "        if score is \"accuracy\":\n",
    "            scoring = score\n",
    "        else:\n",
    "            scoring = '{}_macro'.format(score)\n",
    "\n",
    "        clf = GridSearchCV(SVC(), param_grid, cv=5, scoring=scoring, n_jobs=3)\n",
    "        clf.fit(X_train_lh, y_train_lh)\n",
    "\n",
    "        print(\"Best Parameters set found on data set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on data set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds  = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.3f) for %r\" % (mean, std, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on full SMOTE data set.\")\n",
    "        print(\"The scores on computed on the full TEST data set.\")\n",
    "        print()\n",
    "\n",
    "        y_true, y_pred = y_test_lh, clf.predict(X_test_lh)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true, y_pred = y_test_lh, clf.predict(X_test_lh)\n",
    "print(\"Validatation Score:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confustion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## Parameters for SVMs\n",
    "param_grid = [\n",
    "  {'hidden_layer_sizes': [(256,), (256, 256), (512, 256)] , 'solver': ['adam'],\n",
    "   'activation': ['logistic', 'relu'], 'alpha' : np.linspace(.00005, .005, 4),\n",
    "  }\n",
    " ]\n",
    "\n",
    "scores = ['precision', 'recall', 'accuracy']\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        print(\"## Tuning hyper-parameters for {}\".format(score))\n",
    "        print()\n",
    "\n",
    "        if score is \"accuracy\":\n",
    "            scoring = score\n",
    "        else:\n",
    "            scoring = '{}_macro'.format(score)\n",
    "\n",
    "        clf = GridSearchCV(MLPClassifier(), param_grid, cv=5, scoring=scoring)\n",
    "        clf.fit(X_train_lh2, y_train_lh2)\n",
    "\n",
    "        print(\"Best Parameters set found on data set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on data set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds  = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.3f) for %r\" % (mean, std, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on full SMOTE data set.\")\n",
    "        print(\"The scores on computed on the full TEST data set.\")\n",
    "        print()\n",
    "\n",
    "        y_true, y_pred = y_test_lh2, clf.predict(X_test_lh2)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_test_temp = np.concatenate((X_test_lh2, X_valid_lh2))\n",
    "y_test_temp = np.concatenate((y_test_lh2, y_valid_lh2))\n",
    "y_true, y_pred = y_test_temp, clf.predict(X_test_temp)\n",
    "print(\"Validatation Score:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confustion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "172px",
    "width": "169px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

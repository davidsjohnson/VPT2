{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Piano Tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Project Description\n",
    "\n",
    "This is a notebook for tracking my progress on VPT...\n",
    "\n",
    "- Best Classifier as of 11/30\n",
    "    - SVM {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TODO List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- TODAY\n",
    "    - Decide on RDF model to keep for rest of project\n",
    "    - Work on RDF data and annotations\n",
    "    - Add results to file\n",
    "    - Rewrite RDF for GridSearchCV\n",
    "        - Extend RDF\n",
    "    - Work on ideas for paper\n",
    "        - Visualizations\n",
    "    - Play with CAE\n",
    "    - How to automate this...\n",
    "    - Windowing/Summarizing\n",
    "    \n",
    "- DONE\n",
    "    - ~~Organize RDF data~~\n",
    "    - ~~Generate data from already extracted hands...~~\n",
    "    - ~~Get notebook running on Compute Canada~~\n",
    "    - ~~Get data on Compute Canada~~\n",
    "    - ~~Setup CAE to deal with hand images~~\n",
    "    - ~~setup data for training autoencoder on LH and RH~~\n",
    "    - ~~Train Autoencoder for LH and Rh~~\n",
    "    \n",
    "\n",
    "- Bad Segmentation\n",
    "    - p3c - left hand (not terrible)\n",
    "    - p1s - right hand (shouldn't use)\n",
    "    - p5a - Both could use some work but still caputures most of the left hand (RH not so good...)\n",
    "    - p5c - not good (left hand passable...)\n",
    "    \n",
    "- Add noise to CAE\n",
    "    - http://scikit-image.org/docs/dev/api/skimage.util.html#random-noise\n",
    "    \n",
    "- ~~Multiple Participants~~\n",
    "    - ~~have one holdout set participant~~\n",
    "        - ~~Test with p1&2 training p3 testing, then p1&3...~~\n",
    "    - ~~have one holdout set exercise~~\n",
    "\n",
    "- Test with RH too\n",
    "\n",
    "- Windowing data\n",
    "    - Summarize data for classification\n",
    "    - Majority Voting (or with probabilities)\n",
    "\n",
    "- Look for other features\n",
    "    - Others??\n",
    "    - ~~Autoencoder features~~\n",
    "    - ~~HONV~~\n",
    "    \n",
    "- Work on hand segmentation\n",
    "   - See p1e for bad examples\n",
    "   - How to validate segmentation?\n",
    "       - Statistical analysis on length and width ratios\n",
    "       \n",
    "- Visualize !!!\n",
    "    - Input \n",
    "    - Results !!!\n",
    "        - F Scores\n",
    "        - Accuracy\n",
    "        - Try weighted instead of macro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Finish Project Description\n",
    "\n",
    "- ~~Turn into functions~~\n",
    "    \n",
    "- ~~Verify Segmentation~~\n",
    "    - have only done basic verification\n",
    "    \n",
    "- ~~FIRST THING: Test by ignoring training data (p1s) and then using train_test_split on recordings~~\n",
    "    - ~~Data should be ready for spliting~~\n",
    "    \n",
    "- ~~Remove data from testing to find culprit~~\n",
    "    \n",
    "- ~~Track my progress better !!! (duh through notebooks!)~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from vpt.features.features import *\n",
    "import vpt.utils.image_processing as ip\n",
    "import vpt.settings as s\n",
    "import vpt.hand_detection.depth_context_features as dcf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Save Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(testing_p, M, radius, feature_type, data_type):\n",
    "    base = \"data/posture/extracted/\"\n",
    "    data_path = os.path.join(base, \"{}_M{}_rad{:0.2f}_{}_\".format(testing_p, M, radius, feature_type))\n",
    "    data = np.load(data_path + data_type + \"_data_combined.npz\")    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate or Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 5\n",
    "radius = .15\n",
    "feature_type = \"hog\"\n",
    "testing_p = \"p3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X LH (15818, 1089) y LH (15818,) (15818, 180, 180)\n",
      "X RH (15818, 1089) y RH (15818,) (15818, 180, 180)\n",
      "Filenames (15818,)\n"
     ]
    }
   ],
   "source": [
    "#### Load data for a single paricipant\n",
    "data = load_data(\"all_participants\", M, radius, feature_type, \"train\")\n",
    "print(\"X LH\", data[\"X_lh\"].shape, \"y LH\", data[\"y_lh\"].shape, data[\"vis_lhs\"].shape)\n",
    "print(\"X RH\", data[\"X_rh\"].shape, \"y RH\", data[\"y_rh\"].shape, data[\"vis_rhs\"].shape)\n",
    "print(\"Filenames\", data[\"filenames\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p3 Data:\n",
      "LH: (4572, 1089) (4572,)\n",
      "RH: (4572, 1089) (4572,)\n",
      "(4572,)\n",
      "Comb: (9144, 1089) (9144,)\n",
      "(9144,)\n"
     ]
    }
   ],
   "source": [
    "r = re.compile(testing_p)\n",
    "vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "val_p = vmatch(data['filenames'])\n",
    "\n",
    "X_lh = data['X_lh'][val_p]\n",
    "y_lh = data['y_lh'][val_p]\n",
    "X_rh = data['X_rh'][val_p]\n",
    "y_rh = data['y_rh'][val_p]\n",
    "filenames = data['filenames'][val_p]\n",
    "\n",
    "X_comb = np.vstack((X_lh, X_rh))\n",
    "y_comb = np.hstack((y_lh, y_rh))\n",
    "filenames_comb = np.hstack((filenames, filenames))\n",
    "\n",
    "print(\"{} Data:\".format(testing_p))\n",
    "print(\"LH:\", X_lh.shape, y_lh.shape)\n",
    "print(\"RH:\", X_rh.shape, y_rh.shape)\n",
    "print(filenames.shape)\n",
    "print(\"Comb:\", X_comb.shape, y_comb.shape)\n",
    "print(filenames_comb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, LeaveOneGroupOut\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## find and remove all \"static\" data so we can ignore for now\n",
    "# r = re.compile('{}s'.format(testing_p))\n",
    "r = re.compile('p[\\d]s')\n",
    "\n",
    "# remove p#s data\n",
    "vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "rem_static = vmatch(filenames)\n",
    "rem_static_comb = vmatch(filenames_comb)\n",
    "\n",
    "X_lh, y_lh, filenames = X_lh[~rem_static], y_lh[~rem_static], filenames[~rem_static]\n",
    "X_rh, y_rh = X_rh[~rem_static], y_rh[~rem_static]\n",
    "X_comb, y_comb, filenames_comb = X_comb[~rem_static_comb], y_comb[~rem_static_comb], filenames_comb[~rem_static_comb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split on exercise e\n",
    "r = re.compile('p[\\d]e')\n",
    "\n",
    "# remove p#s data\n",
    "vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "split = vmatch(filenames)\n",
    "split_comb = vmatch(filenames_comb)\n",
    "\n",
    "X_lh_train, y_lh_train, filenames_train = X_lh[~split], y_lh[~split], filenames[~split]\n",
    "X_rh_train, y_rh_train, filenames_train = X_rh[~split], y_rh[~split], filenames[~split]\n",
    "X_comb_train, y_comb_train, filenames_comb_train = X_comb[~split_comb], y_comb[~split_comb], filenames_comb[~split_comb]\n",
    "\n",
    "X_lh_test, y_lh_test, filenames_test = X_lh[split], y_lh[split], filenames[split]\n",
    "X_rh_test, y_rh_test, filenames_test = X_rh[split], y_rh[split], filenames[split]\n",
    "X_comb_test, y_comb_test, filenames_comb_test = X_comb[split_comb], y_comb[split_comb], filenames_comb[split_comb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "LH: (2135, 1089) (2135,)\n",
      "(array([0, 1, 2]), array([1238,  865,   32]))\n",
      "RH: (2135, 1089) (2135,)\n",
      "(2135,)\n",
      "(array([0]), array([2135]))\n",
      "Combined: (4270, 1089) (4270,)\n",
      "(4270,)\n",
      "(array([0, 1, 2]), array([3373,  865,   32]))\n",
      "\n",
      "\n",
      "Test Data\n",
      "LH: (515, 1089) (515,)\n",
      "(array([0, 1, 2]), array([ 29, 471,  15]))\n",
      "RH: (515, 1089) (515,)\n",
      "(array([0]), array([515]))\n",
      "Combined: (1030, 1089) (1030,)\n",
      "(array([0, 1, 2]), array([544, 471,  15]))\n",
      "(1030,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data\")\n",
    "print(\"LH:\", X_lh_train.shape, y_lh_train.shape)\n",
    "print(np.unique(y_lh_train, return_counts=True))\n",
    "print(\"RH:\", X_rh_train.shape, y_rh_train.shape)\n",
    "print(filenames_train.shape)\n",
    "print(np.unique(y_rh_train, return_counts=True))\n",
    "print(\"Combined:\", X_comb_train.shape, y_comb_train.shape)\n",
    "print(filenames_comb_train.shape)\n",
    "print(np.unique(y_comb_train, return_counts=True))\n",
    "print()\n",
    "print()\n",
    "print(\"Test Data\")\n",
    "print(\"LH:\", X_lh_test.shape, y_lh_test.shape)\n",
    "print(np.unique(y_lh_test, return_counts=True))\n",
    "print(\"RH:\", X_rh_test.shape, y_rh_test.shape)\n",
    "print(np.unique(y_rh_test, return_counts=True))\n",
    "print(\"Combined:\", X_comb_test.shape, y_comb_test.shape)\n",
    "print(np.unique(y_comb_test, return_counts=True))\n",
    "print(filenames_comb_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# steps = [('PCA', PCA(n_components=1500)), ('SMOTE', SMOTE(kind=\"borderline2\")), (\"SVC\", SVC(C=10, gamma=.00001, kernel='rbf', probability=False))]\n",
    "steps = [('SMOTE', SMOTE(kind=\"borderline2\")), (\"SVC\", SVC(C=1, gamma=.001, kernel='rbf', decision_function_shape='ovo', probability=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LH Classifier\n",
      "Training RH Classifier\n",
      "Training Combined Classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('SMOTE', SMOTE(k=None, k_neighbors=5, kind='borderline2', m=None, m_neighbors=10,\n",
       "   n_jobs=1, out_step=0.5, random_state=None, ratio='auto',\n",
       "   svm_estimator=None)), ('SVC', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training LH Classifier\")\n",
    "pipeline_lh = Pipeline(steps)\n",
    "pipeline_lh.fit(X_lh_train, y_lh_train)\n",
    "\n",
    "print(\"Training RH Classifier\")\n",
    "pipeline_rh = Pipeline(steps)\n",
    "pipeline_rh.fit(X_rh_train, y_rh_train)\n",
    "\n",
    "print(\"Training Combined Classifier\")\n",
    "pipeline_comb = Pipeline(steps)\n",
    "pipeline_comb.fit(X_comb_train, y_comb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting LH..\n",
      "LH Validation Score: 0.557281553398\n",
      "LH Confusion Matrix:\n",
      " [[  0  28   1]\n",
      " [ 35 279 157]\n",
      " [  0   7   8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        29\n",
      "          1       0.89      0.59      0.71       471\n",
      "          2       0.05      0.53      0.09        15\n",
      "\n",
      "avg / total       0.81      0.56      0.65       515\n",
      "\n",
      "Predicting RH...\n",
      "RH Validation Score: 0.988349514563\n",
      "RH Confusion Matrix:\n",
      " [[509   6]\n",
      " [  0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99       515\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.99      0.99       515\n",
      "\n",
      "Predicting Comb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fortjay81/anaconda/deeppath/deeperpath/deeperpath2/deeperpath3/deeper/deeper/deeper/miniconda3/envs/seng474/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comb Validatation Score: 0.772815533981\n",
      "Comb Confustion Matrix:\n",
      " [[509  28   7]\n",
      " [ 35 279 157]\n",
      " [  0   7   8]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.94      0.94       544\n",
      "          1       0.89      0.59      0.71       471\n",
      "          2       0.05      0.53      0.09        15\n",
      "\n",
      "avg / total       0.90      0.77      0.82      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting LH..\")\n",
    "y_lh_true, y_lh_pred = y_lh_test, pipeline_lh.predict(X_lh_test)\n",
    "print(\"LH Validation Score:\", accuracy_score(y_lh_true, y_lh_pred))\n",
    "print(\"LH Confusion Matrix:\\n\", confusion_matrix(y_lh_true, y_lh_pred))\n",
    "print(classification_report(y_lh_true, y_lh_pred))\n",
    "\n",
    "print(\"Predicting RH...\")\n",
    "y_rh_true, y_rh_pred = y_rh_test, pipeline_rh.predict(X_rh_test)\n",
    "print(\"RH Validation Score:\", accuracy_score(y_rh_true, y_rh_pred))\n",
    "print(\"RH Confusion Matrix:\\n\", confusion_matrix(y_rh_true, y_rh_pred))\n",
    "print(classification_report(y_rh_true, y_rh_pred))\n",
    "\n",
    "print(\"Predicting Comb...\")\n",
    "y_comb_true, y_comb_pred = y_comb_test, pipeline_comb.predict(X_comb_test)\n",
    "print(\"Comb Validatation Score:\", accuracy_score(y_comb_true, y_comb_pred))\n",
    "print(\"Comb Confustion Matrix:\\n\", confusion_matrix(y_comb_true, y_comb_pred))\n",
    "print(classification_report(y_comb_true, y_comb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_size = 15\n",
    "y_comb_true_maj = []\n",
    "for i in range(0, y_comb_true.size, window_size):\n",
    "    u, counts = np.unique(y_comb_true[i:i+window_size], return_counts=True)\n",
    "    pred = u[np.argmax(counts)]\n",
    "    y_comb_true_maj.append(pred)\n",
    "    \n",
    "y_comb_true_maj = np.array(y_comb_true_maj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_comb_pred_maj = []\n",
    "for i in range(0, y_comb_pred.size, window_size):\n",
    "    u, counts = np.unique(y_comb_pred[i:i+window_size], return_counts=True)\n",
    "    pred = u[np.argmax(counts)]\n",
    "    y_comb_pred_maj.append(pred)\n",
    "    \n",
    "y_comb_pred_maj = np.array(y_comb_pred_maj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rH Validatation Score: 0.840579710145\n",
      "rH Confustion Matrix:\n",
      " [[35  2  0]\n",
      " [ 2 23  6]\n",
      " [ 0  1  0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95        37\n",
      "          1       0.88      0.74      0.81        31\n",
      "          2       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.90      0.84      0.87        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Comb Maj Validation Score:\", accuracy_score(y_comb_true_maj, y_comb_pred_maj))\n",
    "print(\"Comb Maj Confusion Matrix:\\n\", confusion_matrix(y_comb_true_maj, y_comb_pred_maj))\n",
    "print(classification_report(y_comb_true_maj, y_comb_pred_maj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p3a', 'p3b', 'p3c', 'p3d', 'p3e']\n",
      "(5300,)\n",
      "(array([0, 1, 2, 3, 4]), array([ 880, 1398,  858, 1134, 1030]))\n",
      "[0 0 0 ..., 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "groups_cv = np.ones_like(filenames_comb, dtype=int)*-1\n",
    "\n",
    "group_names = [\"{}{}\".format(testing_p, ex) for ex in [\"a\", \"b\", \"c\", \"d\", \"e\"]]\n",
    "print(group_names)\n",
    "\n",
    "for i, p in enumerate(group_names):\n",
    "    p_num = i\n",
    "    groups_cv[np.where(np.char.find(filenames_comb, p) != -1)] = p_num\n",
    "    \n",
    "print(groups_cv.shape)\n",
    "print(np.unique(groups_cv, return_counts=True))\n",
    "print(groups_cv[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fortjay81/anaconda/deeppath/deeperpath/deeperpath2/deeperpath3/deeper/deeper/deeper/miniconda3/envs/seng474/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/fortjay81/anaconda/deeppath/deeperpath/deeperpath2/deeperpath3/deeper/deeper/deeper/miniconda3/envs/seng474/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_macro=0.28887988109714907, accuracy=0.7646638054363376, total=  43.1s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_macro=0.39142461964038733, accuracy=0.6431818181818182, total= 1.2min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fortjay81/anaconda/deeppath/deeperpath/deeperpath2/deeperpath3/deeper/deeper/deeper/miniconda3/envs/seng474/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_macro=0.9906751800027169, accuracy=0.9906759906759907, total= 1.4min\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   3 out of   5 | elapsed:  3.5min remaining:  2.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  , f1_macro=0.3618298272774185, accuracy=0.7945326278659612, total= 1.1min\n",
      "[CV] ...... , f1_macro=0.5317005822678431, accuracy=0.8, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  5.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  5.4min finished\n"
     ]
    }
   ],
   "source": [
    "steps = [('SMOTE', SMOTE(kind=\"borderline2\")), (\"SVC\", SVC(C=1, gamma=.001, kernel='rbf', probability=False))]\n",
    "pipeline = Pipeline(steps)\n",
    "scoring = (\"f1_macro\", \"accuracy\")\n",
    "logo = LeaveOneGroupOut()\n",
    "scores = cross_validate(pipeline, X_comb, y_comb, cv=logo.split(X_comb, y_comb, groups=groups_cv), scoring=scoring, n_jobs=2, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time [ 62.86090612  34.10787606  74.74845695  54.09495902  62.15966296]\n",
      "score_time [  9.10481787   9.04074192  10.34519887  10.97806787  10.70870805]\n",
      "test_f1_macro [ 0.39142462  0.28887988  0.99067518  0.36182983  0.53170058]\n",
      "train_f1_macro [ 0.72207101  0.81161267  0.73108645  0.80671811  0.6966369 ]\n",
      "test_accuracy [ 0.64318182  0.76466381  0.99067599  0.79453263  0.8       ]\n",
      "train_accuracy [ 0.85475113  0.89800103  0.85772175  0.91238598  0.86135831]\n"
     ]
    }
   ],
   "source": [
    "for k, v in scores.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### CV #: 0 - Testing Group #: [0] ####\n",
      "Training...\n",
      "Predicting...\n",
      "Comb Validation Score: 0.655681818182\n",
      "Comb Confusion Matrix:\n",
      " [[577 303]\n",
      " [  0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.66      0.79       880\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.66      0.79       880\n",
      "\n",
      "#### CV #: 1 - Testing Group #: [1] ####\n",
      "Training...\n",
      "Predicting...\n",
      "Comb Validation Score: 0.764663805436\n",
      "Comb Confusion Matrix:\n",
      " [[1069   29    0]\n",
      " [ 268    0    0]\n",
      " [  32    0    0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.97      0.87      1098\n",
      "          1       0.00      0.00      0.00       268\n",
      "          2       0.00      0.00      0.00        32\n",
      "\n",
      "avg / total       0.61      0.76      0.68      1398\n",
      "\n",
      "#### CV #: 2 - Testing Group #: [2] ####\n",
      "Training...\n",
      "Predicting...\n",
      "Comb Validation Score: 0.993006993007\n",
      "Comb Confusion Matrix:\n",
      " [[429   0]\n",
      " [  6 423]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       429\n",
      "          1       1.00      0.99      0.99       429\n",
      "\n",
      "avg / total       0.99      0.99      0.99       858\n",
      "\n",
      "#### CV #: 3 - Testing Group #: [3] ####\n",
      "Training...\n",
      "Predicting...\n",
      "Comb Validation Score: 0.811287477954\n",
      "Comb Confusion Matrix:\n",
      " [[893  62  11]\n",
      " [137  27   4]\n",
      " [  0   0   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89       966\n",
      "          1       0.30      0.16      0.21       168\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.78      0.81      0.79      1134\n",
      "\n",
      "#### CV #: 4 - Testing Group #: [4] ####\n",
      "Training...\n",
      "Predicting...\n",
      "Comb Validation Score: 0.802912621359\n",
      "Comb Confusion Matrix:\n",
      " [[516  25   3]\n",
      " [160 311   0]\n",
      " [  7   8   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.95      0.84       544\n",
      "          1       0.90      0.66      0.76       471\n",
      "          2       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.81      0.80      0.79      1030\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = [('SMOTE', SMOTE(kind=\"borderline2\")), (\"SVC\", SVC(C=1, gamma=.001, kernel='rbf', probability=False))]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "logo = LeaveOneGroupOut()\n",
    "for i, (train_idxs, test_idxs) in enumerate(logo.split(X_comb, y_comb, groups=groups_cv)):\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        print(\"#### CV #: {} - Testing Group #: {} ####\".format(i, np.unique(groups_cv[test_idxs])))\n",
    "        print(\"Training...\")\n",
    "        pipeline.fit(X_comb[train_idxs], y_comb[train_idxs])\n",
    "        print(\"Predicting...\")\n",
    "        y_true, y_pred = y_comb[test_idxs], pipeline.predict(X_comb[test_idxs])\n",
    "        print(\"Comb Validation Score:\", accuracy_score(y_true, y_pred))\n",
    "        print(\"Comb Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "        print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parameters for SVMs\n",
    "# steps = [('SMOTE', SMOTE()), (\"SVC\", SVC())]\n",
    "# param_grid = [\n",
    "# #   {'SVC__C': [1, 10, 100], 'SVC__kernel': ['linear'], 'SMOTE__kind': ['regular', 'borderline1', 'borderline2', 'svm']},\n",
    "# #   {'SVC__C': [1, 10, 100], 'SVC__gamma': [.0001, .001, .01, .1], 'SVC__kernel': ['rbf'], 'SMOTE__kind': ['regular', 'borderline1', 'borderline2', 'svm']},\n",
    "# #   {'SVC__C': [10, 100], 'SVC__gamma': [.000005, .00001, .00005,], 'SVC__kernel': ['rbf'], 'SMOTE__kind': ['regular', 'borderline1', 'borderline2']},\n",
    "#  ]\n",
    "\n",
    "steps = [('SMOTE', SMOTEENN()), (\"SVC\", SVC())]\n",
    "param_grid = [\n",
    "  {'SVC__C': [1, 10, 100, 1000], 'SVC__kernel': ['linear'], 'SMOTE__smote': [SMOTE(kind='regular'), SMOTE(kind='borderline1'), SMOTE(kind='borderline2'), SMOTE(kind='svm')]},\n",
    "  {'SVC__C': [1, 10, 100, 1000], 'SVC__gamma': [.0001, .001, .01, .1], 'SVC__kernel': ['rbf'], 'SMOTE__smote': [SMOTE(kind='regular'), SMOTE(kind='borderline1'), SMOTE(kind='borderline2'), SMOTE(kind='svm')]},\n",
    " ]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "scores = ['f1', 'accuracy']\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Tuning hyper-parameters for f1\n",
      "\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV] SMOTE__smote=SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,\n",
      "   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None), SVC__C=1, SVC__kernel=linear \n",
      "[CV] SMOTE__smote=SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10, n_jobs=1,\n",
      "   out_step=0.5, random_state=None, ratio='auto', svm_estimator=None), SVC__C=1, SVC__kernel=linear \n"
     ]
    }
   ],
   "source": [
    "# Hyper Parameter Tuning\n",
    "for score in scores:\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        print(\"## Tuning hyper-parameters for {}\".format(score))\n",
    "        print()\n",
    "\n",
    "        if score is \"accuracy\":\n",
    "            scoring = score\n",
    "        else:\n",
    "            scoring = '{}_macro'.format(score)      \n",
    "        \n",
    "        #### TRAIN COMBINED LH & RH\n",
    "        clf_comb = GridSearchCV(pipeline, param_grid, cv=logo.split(X_comb, y_comb, groups=groups_cv), scoring=scoring, n_jobs=2, verbose=10)\n",
    "        clf_comb.fit(X_comb, y_comb)\n",
    "\n",
    "        print(\"Best Combined Parameters set found on data set:\")\n",
    "        print()\n",
    "        print(clf_comb.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on data set:\")\n",
    "        print()\n",
    "        means = clf_comb.cv_results_['mean_test_score']\n",
    "        stds  = clf_comb.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf_comb.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.3f) for %r\" % (mean, std, params))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {
    "height": "172px",
    "width": "169px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
